{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae1f50ec",
   "metadata": {},
   "source": [
    "# My first AutoGen project: Root cause analysis for pH value low - Task solved with provided function of time series analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a71fa36",
   "metadata": {},
   "source": [
    "AutoGen offers conversable agents powered by LLM, tool, or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation. Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "The use case is the following: a pH value low alert has been fired by some senser and notified a Chatbot (AssistantAgent) which in turn dispatch a UserProxyAgent to get the time series dataset, conduct a dynamic lower band calculation. If the dataset present datapoints with values lower than the lower band. If so, then calculate the estimated time the drop happened. Based on the results, the agent will suggest making a 'Rate Change'.\n",
    "  \n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install `pyautogen`:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b803c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"pyautogen>=0.2.3\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ebd2397",
   "metadata": {},
   "source": [
    "## Set Open AI API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dca301a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "import autogen\n",
    "from autogen.cache import Cache\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"./OAI_CONFIG_LIST.json\"  # All needed OpenAI info is in this file\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92fde41f",
   "metadata": {},
   "source": [
    "The config list looks like the following:\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo-16k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2024-02-01',\n",
    "        'tags': ['tool', '3.5-tool'],\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b9526e7",
   "metadata": {},
   "source": [
    "## Making Function Calls\n",
    "\n",
    "In this example, we demonstrate function call execution with `AssistantAgent` and `UserProxyAgent`. With the new \"function_call\" feature, we define functions and specify the description of the function in the OpenAI config for the `AssistantAgent`. Then we register the functions in `UserProxyAgent`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fb85afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "chatbot = autogen.AssistantAgent(\n",
    "    name=\"chatbot\",\n",
    "    system_message=\"For pH value low tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\" and configure it to not use docker\n",
    "my_code_execution_config = dict(use_docker=False)\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config=my_code_execution_config,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_time(row1, row2, lower_band):\n",
    "    time_diff = (row2['time'] - row1['time']).total_seconds()\n",
    "    ph_diff = row2['pH'] - row1['pH']\n",
    "    time_to_lower_band = (lower_band - row1['pH']) * time_diff / ph_diff\n",
    "    exact_time = row1['time'] + pd.Timedelta(seconds=time_to_lower_band)\n",
    "    return exact_time\n",
    "\n",
    "def drop_time(std=1.0) -> str:\n",
    "    # Sample data\n",
    "    data = {\n",
    "        'time': pd.date_range(start='2023-01-01', periods=10, freq='H'),\n",
    "        'pH': [7.0, 6.8, 6.5, 6.2, 6.0, 5.8, 5.5, 5.3, 5.0, 4.8]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate mean and standard deviation of pH values\n",
    "    mean_ph = np.mean(df['pH'])\n",
    "    std_ph = np.std(df['pH'])\n",
    "\n",
    "    # Set lower band as 2 standard deviations below the mean\n",
    "    lower_band = mean_ph - 1.0 * std\n",
    "    print(f\"Calculated lower band: {lower_band}\")\n",
    "    \n",
    "    # Identify pH drops below the lower band value\n",
    "    df['below_lower_band'] = df['pH'] < lower_band\n",
    "    \n",
    "    # Find the exact time when pH drops below the lower band value using interpolation\n",
    "    drop_times = []\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i-1, 'pH'] >= lower_band and df.loc[i, 'pH'] < lower_band:\n",
    "            exact_time = interpolate_time(df.loc[i-1], df.loc[i], lower_band)\n",
    "            drop_times.append(exact_time)\n",
    "\n",
    "    for time in drop_times:\n",
    "        if time != None:\n",
    "            print(\"Exact times when pH drops below the lower band value:\")\n",
    "            print(time)\n",
    "            return str(time)\n",
    "        else:\n",
    "            print(\"No exact time found.\")\n",
    "            return None\n",
    "\n",
    "@user_proxy.register_for_execution()\n",
    "@chatbot.register_for_llm(description=\"pH Low ROA.\")\n",
    "def pHLowROA(\n",
    "    DropTime: str = \"A RATE CHANGE action is needed as the stimated time of pH drop below the dynamic lower band at 1 standard deviation is:\"\n",
    ") -> str:\n",
    "    dropped_at = drop_time()\n",
    "    if dropped_at == None:\n",
    "        return \"No exact time found and thus no action needed.\"\n",
    "    else:\n",
    "        return f\"{DropTime} {dropped_at}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39464dc3",
   "metadata": {},
   "source": [
    "The decorator `@chatbot.register_for_llm()` reads the annotated signature of the function `currency_calculator` and generates the following JSON schema used by OpenAI API to suggest calling the function. We can check the JSON schema generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e52bbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'description': 'pH Low ROA.',\n",
       "   'name': 'pHLowROA',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'DropTime': {'type': 'string',\n",
       "      'default': 'A RATE CHANGE action is needed as the stimated time of pH drop below the dynamic lower band at 1 standard deviation is:',\n",
       "      'description': 'DropTime'}},\n",
       "    'required': []}}}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.llm_config[\"tools\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662bd12a",
   "metadata": {},
   "source": [
    "The decorator `@user_proxy.register_for_execution()` maps the name of the function to be proposed by OpenAI API to the actual implementation. The function mapped is wrapped since we also automatically handle serialization of the output of function as follows:\n",
    "\n",
    "- string are untouched, and\n",
    "\n",
    "- objects of the Pydantic BaseModel type are serialized to JSON.\n",
    "\n",
    "We can check the correctness of function map by using `._origin` property of the wrapped function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd943369",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user_proxy.function_map[\"pHLowROA\"]._origin == pHLowROA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a09c9",
   "metadata": {},
   "source": [
    "Finally, we can use this function to accurately calculate exchange amounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5518947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "'An pH value low' alert has been fired.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchatbot\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_MgqUAHL6FaMzqI4WAbNz7Ihm): pHLowROA *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"DropTime\": \"A RATE CHANGE action is needed as the estimated time of pH drop below the dynamic lower band at 1 standard deviation is: 30 minutes.\"\n",
      "}\n",
      "\u001b[32m*************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION pHLowROA...\u001b[0m\n",
      "Calculated lower band: 4.89\n",
      "Exact times when pH drops below the lower band value:\n",
      "2023-01-01 08:33:00\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_MgqUAHL6FaMzqI4WAbNz7Ihm) *****\u001b[0m\n",
      "A RATE CHANGE action is needed as the estimated time of pH drop below the dynamic lower band at 1 standard deviation is: 30 minutes. 2023-01-01 08:33:00\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchatbot\u001b[0m (to user_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with Cache.disk() as cache:\n",
    "    # start the conversation\n",
    "    res = user_proxy.initiate_chat(\n",
    "        chatbot, message=\"'An pH value low' alert has been fired.\", summary_method=\"reflection_with_llm\", cache=cache\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b5a0edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat summary: A RATE CHANGE action is needed as the estimated time of pH drop below the dynamic lower band at 1 standard deviation is 30 minutes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chat summary:\", res.summary)"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Learn how to register function calls using AssistantAgent and UserProxyAgent in AutoGen.",
   "tags": [
    "function call",
    "tool use"
   ]
  },
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
